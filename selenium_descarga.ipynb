{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Función para extraer el nombre del anime desde la URL\n",
    "def extract_anime_name(url):\n",
    "    # Eliminar la parte inicial de la URL hasta \"/manga/\"\n",
    "    parts = url.split('/manga/')\n",
    "    if len(parts) > 1:\n",
    "        # Obtener la parte después de \"/manga/\"\n",
    "        name = parts[1].split('/')[0]\n",
    "        return name.replace('-', ' ').title()\n",
    "    return None\n",
    "\n",
    "\n",
    "\n",
    "def extract_segmento_url(url, x , i):\n",
    "    # Eliminar la parte inicial de la URL hasta \"/manga/\"\n",
    "    parts = url.split('/')\n",
    "    if len(parts) > 1:\n",
    "        \n",
    "        return '/'.join(parts[:6])+'/'+x+'/'+i\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archivo CSV guardado en: d:\\todo relacionado a mangas\\script_descarga\\Goblin Slayer Year One\\dataset\\capitulos_complt.csv\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "\n",
    "\n",
    "# Función para extraer el nombre del anime desde la URL\n",
    "def extract_anime_name(url):\n",
    "    # Eliminar la parte inicial de la URL hasta \"/manga/\"\n",
    "    parts = url.split('/manga/')\n",
    "    if len(parts) > 1:\n",
    "        # Obtener la parte después de \"/manga/\"\n",
    "        name = parts[1].split('/')[0]\n",
    "        return name.replace('-', ' ').title()\n",
    "    return None\n",
    "\n",
    "\n",
    "\n",
    "def extract_segmento_url(url, x , i):\n",
    "    # Eliminar la parte inicial de la URL hasta \"/manga/\"\n",
    "    parts = url.split('/')\n",
    "    if len(parts) > 1:\n",
    "        \n",
    "        return '/'.join(parts[:6])+'/'+x+'/'+i\n",
    "    return None\n",
    "\n",
    "# Configuración del WebDriver\n",
    "chrome_options = Options()\n",
    "# chrome_options.add_argument(\"--headless\")  # Ejecuta el navegador en segundo plano\n",
    "chrome_options.add_argument(\"--no-sandbox\")  # Opcional: Soluciona problemas en algunos entornos\n",
    "chrome_options.add_argument(\"--disable-dev-shm-usage\")  # Opcional: Mejora el rendimiento en algunos entornos\n",
    "\n",
    "driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()), options=chrome_options)\n",
    "\n",
    "# URL de la página web\n",
    "url = 'https://inmanga.com/ver/manga/Goblin-Slayer-Year-One/1/7d2722f2-ed53-4198-9d48-b98660ae860d'  # Reemplaza con la URL de tu página\n",
    "\n",
    "# url = 'https://inmanga.com/ver/manga/Dragon-Ball-Z-Full-Color/1/2855add2-1f48-41b5-87b1-fc08cb049456'\n",
    "\n",
    "# Extrae el nombre del anime desde la URL\n",
    "anime_name = extract_anime_name(url)\n",
    "\n",
    "# Limpiar el nombre del anime para que sea válido como nombre de directorio\n",
    "anime_name_clean = \"\".join(char for char in anime_name if char.isalnum() or char.isspace()).replace(\" \", \"_\")\n",
    "\n",
    "# Abre la página web\n",
    "driver.get(url)\n",
    "\n",
    "# Usa una espera explícita para asegurarte de que el elemento esté presente\n",
    "try:\n",
    "    select_element = WebDriverWait(driver, 10).until(\n",
    "        EC.presence_of_element_located((By.XPATH, '//*[@id=\"ChapList\"]'))\n",
    "    )\n",
    "\n",
    "    # Encuentra todas las opciones dentro del <select>\n",
    "    options = select_element.find_elements(By.TAG_NAME, 'option')\n",
    "\n",
    "    cod = []\n",
    "    capitulo = []\n",
    "\n",
    "    # Extrae el value y el texto de cada opción\n",
    "    for option in options:\n",
    "        cod.append(option.get_attribute('value'))\n",
    "        capitulo.append(option.text)\n",
    "\n",
    "    capitulos_complt = {\"capitulo\" : [], \"paginas\" : []}\n",
    "\n",
    "    for x, i in zip(capitulo, cod):\n",
    "        # Abre la página web\n",
    "        driver.get(extract_segmento_url(url,x,i))  # Reemplaza con la URL de tu página\n",
    "\n",
    "        # Usa una espera explícita para asegurarte de que el elemento esté presente\n",
    "        try:\n",
    "            select_element = WebDriverWait(driver, 10).until(\n",
    "                EC.presence_of_element_located((By.XPATH, '//*[@id=\"PageList\"]'))\n",
    "            )\n",
    "\n",
    "            # Encuentra todas las opciones dentro del <select>\n",
    "            options = select_element.find_elements(By.TAG_NAME, 'option')\n",
    "\n",
    "            pagina = [opt.text for opt in options]\n",
    "\n",
    "            boton_next = WebDriverWait(driver, 10).until(\n",
    "                EC.element_to_be_clickable((By.XPATH, '/html/body/div/section/div/div/div[2]/div[1]/div/div/div[5]/div/button[2]'))\n",
    "            )\n",
    "\n",
    "            for _ in range(len(pagina) - 1):\n",
    "                boton_next.click()\n",
    "                # time.sleep(2)  # Espera para que se cargue la nueva página\n",
    "\n",
    "            url_paginas = []\n",
    "\n",
    "            for idx in range(1, len(pagina) + 1):  # Asumiendo que los índices empiezan en 1\n",
    "                try:\n",
    "                    # Encuentra el elemento <a> en base al índice\n",
    "                    src_pag = WebDriverWait(driver, 10).until(\n",
    "                        EC.presence_of_element_located((By.XPATH, f'/html/body/div/section/div/div/div[2]/div[2]/div[1]/a[{idx}]'))\n",
    "                    )\n",
    "\n",
    "                    # Encuentra el elemento <img> dentro del <a>\n",
    "                    img_element = src_pag.find_element(By.TAG_NAME, 'img')\n",
    "\n",
    "                    # Obtén el atributo 'src' del <img>\n",
    "                    src = img_element.get_attribute('src')\n",
    "\n",
    "                    url_paginas.append(src)\n",
    "                except Exception as e:\n",
    "                    print(f\"Error al procesar el elemento {idx}: {e}\")\n",
    "\n",
    "            capitulos_complt[\"capitulo\"].append(x)\n",
    "            capitulos_complt[\"paginas\"].append(url_paginas)\n",
    "            # capitulos_complt[x] = url_paginas\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error al procesar la página {x}/{i}: {e}\")\n",
    "        break\n",
    "\n",
    "finally:\n",
    "    driver.quit()\n",
    "\n",
    "# Crear DataFrame\n",
    "df = pd.DataFrame(capitulos_complt)\n",
    "\n",
    "# Agregar columna con el nombre del anime\n",
    "df.insert(0, 'anime', anime_name)\n",
    "\n",
    "# Crear carpetas usando os.makedirs\n",
    "base_path = os.path.join(os.getcwd(), \"mangas\", anime_name, \"dataset\")\n",
    "os.makedirs(base_path, exist_ok=True)\n",
    "\n",
    "# Ruta completa para el archivo CSV\n",
    "csv_path = os.path.join(base_path, \"capitulos_completos.csv\")\n",
    "\n",
    "# Exportar el DataFrame a CSV\n",
    "df.to_csv(csv_path, index=False)\n",
    "\n",
    "print(f\"Archivo CSV guardado en: {csv_path}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
